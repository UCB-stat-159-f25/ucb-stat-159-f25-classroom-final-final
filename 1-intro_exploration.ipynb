{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03bfb641-744d-40d0-ba47-d504b369ef3c",
   "metadata": {},
   "source": [
    "# Part 1: Data Preprocessing and Exploration\n",
    "This final project is based around the [Open Psychometrics \"Which Character\" Quiz](https://openpsychometrics.org/tests/characters/documentation/). The quiz follows a standard internet format: Respondents assess themselves on series of opposed traits (e.g., are you more selfish or altruistic?), and at the end of the quiz, they are presented with their most similar fictional character (e.g., Batman or Buffy the Vampire Slayer). After the quiz has been completed, users are invited to rate the personalities of the characters themselves (e.g., is Batman more altruistic or selfish?). Open Psychometrics researchers have aggregated the ratings of 2,125 characters across 500 dimensions on a 100-point scale. The aggregate ratings are based on 3,386,031 user responses. Our work is inspired by the work of the [Vermont Computational Story Lab](https://compstorylab.org/archetypometrics/).\n",
    "\n",
    "In this first notebook, we'll import, clean, and prepare the data for exploration. We'll conduct light exploration to assess the contents of the data. The dataset `characters-aggregated-scores.csv` was downloaded from [Open Psychometrics](https://openpsychometrics.org/tests/characters/data/). Supplemental datasets (to provide variable and character names) were developed based on the online documentation, which is available here as an `.html` file in the `data` folder. _Note: If downloading an updated version of the dataset, the data formats, character names, and variables might have changed._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4641a6-b160-4359-afe4-0f7254ec67ee",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd86f6c-8f01-415c-bfff-037b507007af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd5a876-0400-4755-82de-c2dbd2eaf4d7",
   "metadata": {},
   "source": [
    "### Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "395f1ed3-2cc8-467a-a8c5-6503e868c899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BAP1</th>\n",
       "      <th>BAP2</th>\n",
       "      <th>BAP3</th>\n",
       "      <th>BAP4</th>\n",
       "      <th>BAP5</th>\n",
       "      <th>BAP6</th>\n",
       "      <th>BAP7</th>\n",
       "      <th>BAP8</th>\n",
       "      <th>BAP9</th>\n",
       "      <th>...</th>\n",
       "      <th>BAP491</th>\n",
       "      <th>BAP492</th>\n",
       "      <th>BAP493</th>\n",
       "      <th>BAP494</th>\n",
       "      <th>BAP495</th>\n",
       "      <th>BAP496</th>\n",
       "      <th>BAP497</th>\n",
       "      <th>BAP498</th>\n",
       "      <th>BAP499</th>\n",
       "      <th>BAP500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HML/1</td>\n",
       "      <td>62.4</td>\n",
       "      <td>69.8</td>\n",
       "      <td>92.6</td>\n",
       "      <td>31.9</td>\n",
       "      <td>61.2</td>\n",
       "      <td>53.5</td>\n",
       "      <td>28.8</td>\n",
       "      <td>44.0</td>\n",
       "      <td>63.9</td>\n",
       "      <td>...</td>\n",
       "      <td>27.5</td>\n",
       "      <td>78.8</td>\n",
       "      <td>40.5</td>\n",
       "      <td>53.4</td>\n",
       "      <td>77.4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>56.3</td>\n",
       "      <td>51.4</td>\n",
       "      <td>87.4</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HML/2</td>\n",
       "      <td>79.1</td>\n",
       "      <td>62.2</td>\n",
       "      <td>68.5</td>\n",
       "      <td>78.1</td>\n",
       "      <td>36.9</td>\n",
       "      <td>40.3</td>\n",
       "      <td>42.6</td>\n",
       "      <td>40.4</td>\n",
       "      <td>23.3</td>\n",
       "      <td>...</td>\n",
       "      <td>42.8</td>\n",
       "      <td>23.9</td>\n",
       "      <td>84.9</td>\n",
       "      <td>73.7</td>\n",
       "      <td>49.0</td>\n",
       "      <td>73.7</td>\n",
       "      <td>21.1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HML/3</td>\n",
       "      <td>83.2</td>\n",
       "      <td>85.3</td>\n",
       "      <td>69.4</td>\n",
       "      <td>21.8</td>\n",
       "      <td>39.1</td>\n",
       "      <td>35.8</td>\n",
       "      <td>49.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>59.3</td>\n",
       "      <td>...</td>\n",
       "      <td>11.3</td>\n",
       "      <td>29.7</td>\n",
       "      <td>50.7</td>\n",
       "      <td>78.6</td>\n",
       "      <td>68.2</td>\n",
       "      <td>20.3</td>\n",
       "      <td>31.6</td>\n",
       "      <td>48.7</td>\n",
       "      <td>74.3</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HML/4</td>\n",
       "      <td>72.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>67.1</td>\n",
       "      <td>28.2</td>\n",
       "      <td>66.3</td>\n",
       "      <td>47.9</td>\n",
       "      <td>30.4</td>\n",
       "      <td>18.1</td>\n",
       "      <td>34.4</td>\n",
       "      <td>...</td>\n",
       "      <td>31.6</td>\n",
       "      <td>22.2</td>\n",
       "      <td>75.7</td>\n",
       "      <td>60.4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>55.9</td>\n",
       "      <td>25.5</td>\n",
       "      <td>48.2</td>\n",
       "      <td>80.1</td>\n",
       "      <td>49.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HML/5</td>\n",
       "      <td>40.7</td>\n",
       "      <td>48.1</td>\n",
       "      <td>81.8</td>\n",
       "      <td>90.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>59.3</td>\n",
       "      <td>41.1</td>\n",
       "      <td>73.9</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.6</td>\n",
       "      <td>42.4</td>\n",
       "      <td>75.0</td>\n",
       "      <td>61.7</td>\n",
       "      <td>61.3</td>\n",
       "      <td>15.1</td>\n",
       "      <td>57.3</td>\n",
       "      <td>54.7</td>\n",
       "      <td>90.3</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  BAP1  BAP2  BAP3  BAP4  BAP5  BAP6  BAP7  BAP8  BAP9  ...  BAP491  \\\n",
       "0  HML/1  62.4  69.8  92.6  31.9  61.2  53.5  28.8  44.0  63.9  ...    27.5   \n",
       "1  HML/2  79.1  62.2  68.5  78.1  36.9  40.3  42.6  40.4  23.3  ...    42.8   \n",
       "2  HML/3  83.2  85.3  69.4  21.8  39.1  35.8  49.9  16.0  59.3  ...    11.3   \n",
       "3  HML/4  72.5  65.0  67.1  28.2  66.3  47.9  30.4  18.1  34.4  ...    31.6   \n",
       "4  HML/5  40.7  48.1  81.8  90.0  52.6  59.3  41.1  73.9  43.0  ...    35.6   \n",
       "\n",
       "   BAP492  BAP493  BAP494  BAP495  BAP496  BAP497  BAP498  BAP499  BAP500  \n",
       "0    78.8    40.5    53.4    77.4    14.0    56.3    51.4    87.4     8.2  \n",
       "1    23.9    84.9    73.7    49.0    73.7    21.1    71.0    26.3    63.3  \n",
       "2    29.7    50.7    78.6    68.2    20.3    31.6    48.7    74.3    55.0  \n",
       "3    22.2    75.7    60.4    79.0    55.9    25.5    48.2    80.1    49.6  \n",
       "4    42.4    75.0    61.7    61.3    15.1    57.3    54.7    90.3    24.9  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/characters-aggregated-scores.csv\", sep=\",\")\n",
    "var_key = pd.read_csv(\"data/variable-key.csv\")\n",
    "char_key = pd.read_csv(\"data/character-key.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f53261-40ff-4049-b450-eeb1561d0223",
   "metadata": {},
   "source": [
    "The columns represent each dimension on which the characters were rated—or \"binary adjective pairs\" (BAPs). We'll make these more legible using our `var_key` and provide actual names for the characters. We rename the columns based on the `var_key`, and then we drop a few specific columns: The authors used emojis for some of the BAPs, which are hard to interpret and cause problems with visualization, so they have been labelled \"INVALID.\" In addition, the authors accidentally included the \"hard-soft\" pair twice, so only the first pair is kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6f1d000-6858-4171-b3a2-97e6ce2c4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(char_key, data, on=\"id\") # merge ratings with character information\n",
    "data.columns = [\"id\"] + [\"character\"] + [\"source\"] + var_key[\"scale\"].to_list() # rename columns\n",
    "data = data.loc[:,~data.columns.str.startswith('INVALID')]\n",
    "data = data.loc[:, ~data.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0749e8e-98de-4734-b9f2-cd7971365c16",
   "metadata": {},
   "source": [
    "In the datafame below, the low end of the 100-point scale correspond to left-hand \"adjective\", and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "36e18b66-222c-4614-9ed9-e6fdff88111f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>character</th>\n",
       "      <th>source</th>\n",
       "      <th>playful_serious</th>\n",
       "      <th>shy_bold</th>\n",
       "      <th>cheery_sorrowful</th>\n",
       "      <th>masculine_feminine</th>\n",
       "      <th>charming_awkward</th>\n",
       "      <th>lewd_tasteful</th>\n",
       "      <th>intellectual_physical</th>\n",
       "      <th>...</th>\n",
       "      <th>cringing-away_welcoming-experience</th>\n",
       "      <th>stereotypical_boundary-breaking</th>\n",
       "      <th>energetic_mellow</th>\n",
       "      <th>hopeful_fearful</th>\n",
       "      <th>likes-change_resists-change</th>\n",
       "      <th>manic_mild</th>\n",
       "      <th>old-fashioned_progressive</th>\n",
       "      <th>gross_hygienic</th>\n",
       "      <th>stable_unstable</th>\n",
       "      <th>overthinker_underthinker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HML/1</td>\n",
       "      <td>Prince Hamlet</td>\n",
       "      <td>Hamlet</td>\n",
       "      <td>62.4</td>\n",
       "      <td>69.8</td>\n",
       "      <td>92.6</td>\n",
       "      <td>31.9</td>\n",
       "      <td>61.2</td>\n",
       "      <td>53.5</td>\n",
       "      <td>28.8</td>\n",
       "      <td>...</td>\n",
       "      <td>27.5</td>\n",
       "      <td>78.8</td>\n",
       "      <td>40.5</td>\n",
       "      <td>53.4</td>\n",
       "      <td>77.4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>56.3</td>\n",
       "      <td>51.4</td>\n",
       "      <td>87.4</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HML/2</td>\n",
       "      <td>Queen Gertrude</td>\n",
       "      <td>Hamlet</td>\n",
       "      <td>79.1</td>\n",
       "      <td>62.2</td>\n",
       "      <td>68.5</td>\n",
       "      <td>78.1</td>\n",
       "      <td>36.9</td>\n",
       "      <td>40.3</td>\n",
       "      <td>42.6</td>\n",
       "      <td>...</td>\n",
       "      <td>42.8</td>\n",
       "      <td>23.9</td>\n",
       "      <td>84.9</td>\n",
       "      <td>73.7</td>\n",
       "      <td>49.0</td>\n",
       "      <td>73.7</td>\n",
       "      <td>21.1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HML/3</td>\n",
       "      <td>King Claudius</td>\n",
       "      <td>Hamlet</td>\n",
       "      <td>83.2</td>\n",
       "      <td>85.3</td>\n",
       "      <td>69.4</td>\n",
       "      <td>21.8</td>\n",
       "      <td>39.1</td>\n",
       "      <td>35.8</td>\n",
       "      <td>49.9</td>\n",
       "      <td>...</td>\n",
       "      <td>11.3</td>\n",
       "      <td>29.7</td>\n",
       "      <td>50.7</td>\n",
       "      <td>78.6</td>\n",
       "      <td>68.2</td>\n",
       "      <td>20.3</td>\n",
       "      <td>31.6</td>\n",
       "      <td>48.7</td>\n",
       "      <td>74.3</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HML/4</td>\n",
       "      <td>Polonius</td>\n",
       "      <td>Hamlet</td>\n",
       "      <td>72.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>67.1</td>\n",
       "      <td>28.2</td>\n",
       "      <td>66.3</td>\n",
       "      <td>47.9</td>\n",
       "      <td>30.4</td>\n",
       "      <td>...</td>\n",
       "      <td>31.6</td>\n",
       "      <td>22.2</td>\n",
       "      <td>75.7</td>\n",
       "      <td>60.4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>55.9</td>\n",
       "      <td>25.5</td>\n",
       "      <td>48.2</td>\n",
       "      <td>80.1</td>\n",
       "      <td>49.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HML/5</td>\n",
       "      <td>Ophelia</td>\n",
       "      <td>Hamlet</td>\n",
       "      <td>40.7</td>\n",
       "      <td>48.1</td>\n",
       "      <td>81.8</td>\n",
       "      <td>90.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>59.3</td>\n",
       "      <td>41.1</td>\n",
       "      <td>...</td>\n",
       "      <td>35.6</td>\n",
       "      <td>42.4</td>\n",
       "      <td>75.0</td>\n",
       "      <td>61.7</td>\n",
       "      <td>61.3</td>\n",
       "      <td>15.1</td>\n",
       "      <td>57.3</td>\n",
       "      <td>54.7</td>\n",
       "      <td>90.3</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 467 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       character  source  playful_serious  shy_bold  cheery_sorrowful  \\\n",
       "0  HML/1   Prince Hamlet  Hamlet             62.4      69.8              92.6   \n",
       "1  HML/2  Queen Gertrude  Hamlet             79.1      62.2              68.5   \n",
       "2  HML/3   King Claudius  Hamlet             83.2      85.3              69.4   \n",
       "3  HML/4        Polonius  Hamlet             72.5      65.0              67.1   \n",
       "4  HML/5         Ophelia  Hamlet             40.7      48.1              81.8   \n",
       "\n",
       "   masculine_feminine  charming_awkward  lewd_tasteful  intellectual_physical  \\\n",
       "0                31.9              61.2           53.5                   28.8   \n",
       "1                78.1              36.9           40.3                   42.6   \n",
       "2                21.8              39.1           35.8                   49.9   \n",
       "3                28.2              66.3           47.9                   30.4   \n",
       "4                90.0              52.6           59.3                   41.1   \n",
       "\n",
       "   ...  cringing-away_welcoming-experience  stereotypical_boundary-breaking  \\\n",
       "0  ...                                27.5                             78.8   \n",
       "1  ...                                42.8                             23.9   \n",
       "2  ...                                11.3                             29.7   \n",
       "3  ...                                31.6                             22.2   \n",
       "4  ...                                35.6                             42.4   \n",
       "\n",
       "   energetic_mellow  hopeful_fearful  likes-change_resists-change  manic_mild  \\\n",
       "0              40.5             53.4                         77.4        14.0   \n",
       "1              84.9             73.7                         49.0        73.7   \n",
       "2              50.7             78.6                         68.2        20.3   \n",
       "3              75.7             60.4                         79.0        55.9   \n",
       "4              75.0             61.7                         61.3        15.1   \n",
       "\n",
       "   old-fashioned_progressive  gross_hygienic  stable_unstable  \\\n",
       "0                       56.3            51.4             87.4   \n",
       "1                       21.1            71.0             26.3   \n",
       "2                       31.6            48.7             74.3   \n",
       "3                       25.5            48.2             80.1   \n",
       "4                       57.3            54.7             90.3   \n",
       "\n",
       "   overthinker_underthinker  \n",
       "0                       8.2  \n",
       "1                      63.3  \n",
       "2                      55.0  \n",
       "3                      49.6  \n",
       "4                      24.9  \n",
       "\n",
       "[5 rows x 467 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9907a6c2-2e85-48ee-a496-2b0f4b3c0a24",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c37c373-f676-4cbe-907b-c8a2b800a2b2",
   "metadata": {},
   "source": [
    "What if we want to know the 10 most charming and awkward characters in the dataset? The functions below allow you to input the data and the name of the column you're most interested in. `most_right` will print the highest scores for the right-hand term, while `most_left` will print the highest scores for the left-hand term (which are technically the lowest scores on that dimension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "50c41054-c88b-422e-9cb9-2293072fd534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_right(data, column_name):\n",
    "    most_right = data.nlargest(n=10, columns=[column_name])\n",
    "    most_right = most_right[[\"character\", \"source\", column_name]]\n",
    "    print(most_right)\n",
    "\n",
    "def most_left(data, column_name):\n",
    "    most_right = data.nsmallest(n=10, columns=[column_name])\n",
    "    most_right = most_right[[\"character\", \"source\", column_name]]\n",
    "    print(most_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8bb0dc66-171e-485a-b74c-ccf44478660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                character                        source  charming_awkward\n",
      "816        Emma Pillsbury                          Glee              93.1\n",
      "1264  Mr. William Collins           Pride and Prejudice              93.0\n",
      "762          Tina Belcher                 Bob's Burgers              92.2\n",
      "1016         Kirk Gleason                 Gilmore Girls              91.7\n",
      "2063         Buster Bluth          Arrested Development              91.6\n",
      "909          Stuart Bloom           The Big Bang Theory              91.4\n",
      "1324                James  The End of the F***ing World              91.3\n",
      "345            Jonah Ryan                          Veep              90.8\n",
      "2064         Tobias Funke          Arrested Development              90.8\n",
      "672           Morty Smith                Rick and Morty              90.6\n"
     ]
    }
   ],
   "source": [
    "most_right(data, \"charming_awkward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b6c586a-c40f-4276-89c9-b0a04e00dec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                character                source  charming_awkward\n",
      "1142         Neal Caffrey          White Collar               3.1\n",
      "2092           James Bond  Tommorrow Never Dies               4.4\n",
      "248           Inara Serra    Firefly + Serenity               4.8\n",
      "556   Lucifer Morningstar               Lucifer               6.4\n",
      "1223       Frank Abagnale   Catch Me If You Can               6.5\n",
      "203            Don Draper               Mad Men               6.7\n",
      "1534      Damon Salvatore   The Vampire Diaries               6.8\n",
      "1545             Lagertha               Vikings               6.9\n",
      "207         Joan Holloway               Mad Men               7.4\n",
      "63         Derek Shepherd        Grey's Anatomy               7.7\n"
     ]
    }
   ],
   "source": [
    "most_left(data, \"charming_awkward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db148b43-bb62-424b-852d-839230ce2a74",
   "metadata": {},
   "source": [
    "For Neha, some ideas for data exploration:\n",
    "1. Scores with the highest/lowest averages?\n",
    "2. Correlation matrices?\n",
    "3. highest variance?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
